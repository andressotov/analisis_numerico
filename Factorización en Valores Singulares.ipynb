{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86988a80",
   "metadata": {},
   "source": [
    "# Factorización en Valores Singulares # \n",
    "\n",
    "La descomposición en valores singulares (Singular Value Decomposition, $SVD$) está estrechamente relacionada con la factorización de valores propios-vectores propios $QΛQ^T$ de una matriz definida positiva. Sin embargo, encontramos muchas matrices que no son definidas positivas, por lo que no se puede aplicar dicho criterio. Si consideramos una matriz rectangular (no cuadrada), los valores propios no están definidos en este escenario. Si permitimos que la $Q$ de la izquierda y la $Q$ de la derecha sean dos matrices ortogonales $U$ y $V^T$, entonces cualquier matriz tendrá una descomposición $A=UΣV^T$, donde:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd8ec7",
   "metadata": {},
   "source": [
    "* $Σ$ tiene valores propios de $A^TA$, no de $A$. Estas entradas positivas serán $σ_1,..., σ_r$, que son los valores singulares (propios) de $A$, los cuales ocupan los primeros $r$ lugares de la diagonal principal de $Σ$ cuando $A$ tiene rango $r$. El resto de $Σ$ es cero, \n",
    "\n",
    "* Las columnas de $U$ son los vectores propios de $AA^T$,\n",
    "\n",
    "* las columnas de $V$ son los vectores propios de $A^TA$.\n",
    "\n",
    "* Los valores singulares de $r$ en la diagonal de $Σ$ son las raíces cuadradas de los valores propios distintos de cero de $AA^T$ y $A^TA$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05cbe22",
   "metadata": {},
   "source": [
    "Los vectores propios son vectores que, cuando se multiplican por una matriz, dan como resultado otro vector que tiene la misma dirección, pero escalado en una dirección hacia adelante o hacia atrás por una magnitud del múltiplo del escalador que se puede denominar valor propio. En palabras más simples, el valor propio puede verse como el factor de escala para los vectores propios. \n",
    "\n",
    "Se denomina ecuación propia a la siguiente fórmula:\n",
    "\n",
    "$$ Ax=λx $$\n",
    "\n",
    "En la ecuación anterior, la matriz $A$ actúa sobre el vector $x$ y el resultado es el vector $Ax$, que tiene la misma dirección que el vector original $x$, pero escalado (aumentado/reducido hacia adelante o hacia atrás) por una magnitud de múltiplo escalador, $λ$. El vector $x$ se denomina vector propio de $A$ y $λ$ es su valor propio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ce884",
   "metadata": {},
   "source": [
    "Veamos gráficamente lo que sucede cuando una matriz $A$ actúa sobre un vector $x$. Observe que el nuevo vector $Ax$ tiene una dirección diferente a la del vector $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c9a01",
   "metadata": {},
   "source": [
    "![Producto matriz por vector](GrafProdAx.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf4e18",
   "metadata": {},
   "source": [
    "Si la multiplicación de la matriz por el vector da como resultado otro vector en la misma dirección o en la dirección opuesta pero escalado hacia adelante o hacia atrás por una magnitud del múltiplo del valor propio ($\\lambda$), entonces el vector se denomina vector propio de esa matriz. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5367a",
   "metadata": {},
   "source": [
    "El diagrama siguiente representa el vector propio $x$ de la matriz $A$ porque el vector $Ax$ está en la misma dirección u opuesta a $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7ca1d",
   "metadata": {},
   "source": [
    "![x is eigenvector of A](x_eigenvector_A.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb54dc",
   "metadata": {},
   "source": [
    "Sea $\\lambda$ un número real. Entonces:\n",
    "\n",
    "• Si $\\lambda>0$, $v$ y $Av$ apuntan en la misma dirección.\n",
    "\n",
    "• Si $\\lambda<0$ , $v$ y $Av$ apuntan en direcciones opuestas.\n",
    "\n",
    "• Si $|\\lambda| < 1$, $Av$ es menor que $v$.\n",
    "\n",
    "• Si $|\\lambda| > 1$, $Av$ es mayor que $v$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6322c5",
   "metadata": {},
   "source": [
    "La $SVD$ es muy útil para cálculos numéricamente estables, porque $U$ y $V$ son matrices ortogonales, por lo que no cambian la longitud de un vector. $Σ$ podría multiplicar o dividir un vector por un σ grande, pero al menos ahora tenemos una idea exacta de qué es grande y qué es pequeño. La relación de $\\sigma_{max}/\\sigma_{min}$ es el número que define la condición (i.e., condition number) de una matriz no singular. Para un analista numérico, este pudiera ser el uso más importante de $SVD$.\n",
    "Podemos usar el número de condición de una matriz para determinar la precisión de nuestra solución. Para la ecuación matricial\n",
    "\n",
    "$$ Ax = b$$\n",
    "\n",
    "el error relativo $\\|x\\| < (\\sigma_{max}/\\sigma_{min})\\epsilon_m$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cae288",
   "metadata": {},
   "source": [
    "## ¿Cómo Calcular los Valores y Vectores Propios? ##\n",
    "\n",
    "Para calcular el valor propio y el vector propio de cualquier matriz $A$ debemos:\n",
    "\n",
    "* Calcular uno o más valores propios dependiendo del número de dimensiones de una matriz cuadrada\n",
    "\n",
    "* Determinar los vectores propios correspondientes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa95001f",
   "metadata": {},
   "source": [
    "Para calcular los valores propios, se necesita resolver la siguiente ecuación:\n",
    "\n",
    "$$ Ax=λx \\Rightarrow Ax–λx=0 \\Rightarrow (A–λI)x=0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37bb41",
   "metadata": {},
   "source": [
    "Si el vector propio es distinto de cero, se pueden determinar los valores propios  resolviendo la siguiente ecuación:\n",
    "\n",
    "$$ A–λI=0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581f88f",
   "metadata": {},
   "source": [
    "En la ecuación anterior, $I$ es la matriz identidad y $\\lambda$ es el valor propio. Una vez que se determinan los valores propios, los vectores propios se determinan resolviendo la ecuación $(A–λI)x=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303e3e0",
   "metadata": {},
   "source": [
    "Si se quiere calcular los valores propios de una matriz dada y ésta es pequeña, se puede calcular simbólicamente usando el polinomio característico. Sin embargo, a menudo resulta imposible para matrices extensas, caso en el que se debe usar un método numérico.\n",
    "\n",
    "El polinomio característico de $A$, $p_A(t)$, es el polinomio definido por:\n",
    "\n",
    "$$ p_A(t) = det(A-tI), $$\n",
    "\n",
    "donde $I$ denota la matriz identidad $n \\times n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c90206",
   "metadata": {},
   "source": [
    "Ejemplos:\n",
    "\n",
    "Supongamos que queremos encontrar el polinomio característico de la matriz\n",
    "\n",
    "$$ A={\\begin{pmatrix}2&1\\\\-1&0\\end{pmatrix}}.$$\n",
    "\n",
    "Para ello, debemos calcular el determinante de\n",
    "\n",
    "$$ {\\displaystyle A-tI={\\begin{pmatrix}2-t&1\\\\-1&-t\\end{pmatrix}}=(2-t)(-t)-1(-1)=t^{2}-2t+1=(t-1)^{2}}, $$ \n",
    "\n",
    "Y de esta forma obtenemos el polinomio característico de A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9f14a",
   "metadata": {},
   "source": [
    "Para calcular la descomposición en valores singulares ($SVD$) de una matriz simétrica $A$ podemos utilizar primero el algoritmo $QR$ para encontrar los valores propios de la matriz $AA^⊺$. Luego, utilizamos el método de la potencia inversa para encontrar los vectores propios que corresponden a los valores singulares para $AA^⊺$ y $A^⊺A$. Y finalmente, podemos usar el método de Gram-Schmidt para encontrar una base ortogonal de estos vectores propios para definir las matrices $U$ y $V$. Este es el proceso que se realiza en np.linalg.svd.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb647e0",
   "metadata": {},
   "source": [
    "# Método de las Potencias # \n",
    "\n",
    "El método de las potencias es un método iterativo que calcula sucesivas aproximaciones a los vectores y valores propios de una matriz.\n",
    "\n",
    "El método se usa principalmente para calcular el vector propio correspondiente al mayor de los valores propios en matrices grandes.\n",
    "\n",
    "Para aplicar el método de las potencias se supone que la matriz $A$ de $n \\times n$ tiene $n$ valores característicos ${\\displaystyle \\lambda _{1},\\lambda _{2},...,\\lambda _{n}}$ con un conjunto asociado de vectores característicos linealmente independientes ${\\displaystyle (v^{(1)},v^{(2)},...,v^{(n)})}$. Aún más, se supone que $A$ tiene exactamente un valor característico ${\\displaystyle \\lambda _{1}}$ predominante, cuya magnitud es la mayor, por lo que ${\\displaystyle |\\lambda _{1}|>|\\lambda _{2}|\\geq |\\lambda _{3}|...\\geq |\\lambda _{n}|\\geq 0}$. El método converge lentamente y solo puede determinar uno de los autovectores de la matriz.\n",
    "\n",
    "El método empieza por tomar cualquier vector $x_{0}$ como aproximación inicial al autovector dominante, el cual puede ser escogido aleatoriamente. En cada paso $k$, se calcula \n",
    "\n",
    "$${\\displaystyle x_{k+1}={\\frac {Ax_{k}}{\\|Ax_{k}\\|}}.}$$ \n",
    "\n",
    "Entonces ${\\displaystyle x_{k}}$ converge normalmente al autovector de mayor autovalor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c4e74",
   "metadata": {},
   "source": [
    "Por su parte, el método de potencia inversa (también conocido como el método de iteración inversa) es un algoritmo iterativo para el cálculo de valores propios. Este método permite encontrar un vector propio aproximado a partir de una aproximación al valor propio correspondiente. El método es conceptualmente similar al método de potencia antes explicado. \n",
    "\n",
    "El algoritmo de iteración de potencia inversa comienza con una aproximación $\\mu$ para el valor propio correspondiente al vector propio deseado y un vector $b_{0}$, ya sea un vector seleccionado al azar o una aproximación al vector propio. El método se describe mediante la iteración.\n",
    "\n",
    "$$ b_{{k+1}}={\\frac  {(A-\\mu I)^{{-1}}b_{k}}{C_{k}}},$$\n",
    "\n",
    "donde $C_{k}$ son constantes elegidas comunmente como:\n",
    "\n",
    "$$ C_{k}=\\|(A-\\mu I)^{{-1}}b_{k}\\|. $$\n",
    "\n",
    "Dado que el producto por una constante de los vectores propios se encuentra definido, la elección de $C_{k}$ puede ser arbitraria en teoría. \n",
    "\n",
    "En cada iteración, el vector $b_{k}$ se multiplica por la matriz\n",
    "$(A-\\mu I)^{{-1}}$ y es normalizado. Es la misma fórmula utilizada en el método de la potencia, excepto que se reemplaza la matriz $A$ por $(A-\\mu I)^{{-1}}.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de35640",
   "metadata": {},
   "source": [
    "Sean $\\lambda_1,..., \\lambda_n$ los valores propios de $A$. Supongamos que $\\lambda_1$ es simple y $\\sigma ≈ \\lambda_1$. Entonces\n",
    "\n",
    "$$ µ1 = \\frac{1}{\\lambda_1 − \\sigma}, µ2 = \\frac{1}{\\lambda_2 − \\sigma},..., µn = \\frac{1}{\\lambda_n − \\sigma} $$\n",
    "\n",
    "son valores propios de $(A − \\sigma I)^{−1}$ y $\\mu_1 → ∞$ según $\\sigma → \\lambda_1$. Así transformamos $\\lambda_1$ en un valor propio dominante $\\mu_1$. El método de potencia inversa es simplemente el método de potencia aplicado a $(A − \\sigma I)^{−1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f4e2b",
   "metadata": {},
   "source": [
    "## Propiedades ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032d3cc",
   "metadata": {},
   "source": [
    "## Ejemplos ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc077e",
   "metadata": {},
   "source": [
    "## Bibliografía ##\n",
    "\n",
    "* [Descomposición en valores singulares](https://es.wikipedia.org/wiki/Descomposici%C3%B3n_en_valores_singulares).\n",
    "\n",
    "* [Singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition).\n",
    "\n",
    "* [Singular Value Decomposition](https://johnfoster.pge.utexas.edu/numerical-methods-book/LinearAlgebra_SVD.html).\n",
    "\n",
    "* [Why & When to use Eigenvalues & Eigenvectors?](https://vitalflux.com/why-when-use-eigenvalue-eigenvector/).\n",
    "\n",
    "* [Cap 6 Valores propios y vectores propios](https://www.etsist.upm.es/uploaded/docs_personales/hernandez_heredero_rafael_jose/old/Algebra/ALApC6.pdf).\n",
    "\n",
    "* [Polinomio característico](https://es.wikipedia.org/wiki/Polinomio_caracter%C3%ADstico).\n",
    "\n",
    "* [Inverse Power Method](https://en.wikipedia.org/wiki/Inverse_iteration#:~:text=In%20numerical%20analysis%2C%20inverse%20iteration,similar%20to%20the%20power%20method).\n",
    "\n",
    "* [Método de las potencias](https://es.wikipedia.org/wiki/M%C3%A9todo_de_las_potencias).\n",
    "\n",
    "* [Inverse iteration](https://en.wikipedia.org/wiki/Inverse_iteration#:~:text=In%20numerical%20analysis%2C%20inverse%20iteration,similar%20to%20the%20power%20method).\n",
    "\n",
    "* [Power and inverse power methods](https://math.ntnu.edu.tw/~min/matrix_computation/power_method.pdf).\n",
    "\n",
    "* [Vector, valor y espacio propios](https://es.wikipedia.org/wiki/Vector,_valor_y_espacio_propios).\n",
    "\n",
    "* [Eigenvalues and eigenvectors](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors).\n",
    "\n",
    "* [Scipy sparse linalg svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html)\n",
    "\n",
    "* [Decomposing signals in components (matrix factorization problems)](https://scikit-learn.org/stable/modules/decomposition.html#)\n",
    "\n",
    "* [Sklearn decomposition PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "* [Sklearn decomposition TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)\n",
    "\n",
    "* [Get U, Sigma, V* matrix from Truncated SVD in scikit-learn](https://stackoverflow.com/questions/31523575/get-u-sigma-v-matrix-from-truncated-svd-in-scikit-learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702610c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
